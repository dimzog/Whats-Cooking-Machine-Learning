{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Βασικά imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.18.1 in c:\\users\\dimzog\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from -r requirements.txt (line 1)) (1.18.1)\n",
      "Requirement already satisfied: pandas==1.0.1 in c:\\users\\dimzog\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from -r requirements.txt (line 2)) (1.0.1)\n",
      "Requirement already satisfied: tqdm==4.43.0 in c:\\users\\dimzog\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from -r requirements.txt (line 3)) (4.43.0)\n",
      "Requirement already satisfied: nltk==3.4.5 in c:\\users\\dimzog\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from -r requirements.txt (line 4)) (3.4.5)\n",
      "Requirement already satisfied: scikit-learn==0.22.1 in c:\\users\\dimzog\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from -r requirements.txt (line 5)) (0.22.1)\n",
      "Requirement already satisfied: seaborn==0.10.0 in c:\\users\\dimzog\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from -r requirements.txt (line 6)) (0.10.0)\n",
      "Requirement already satisfied: joblib==0.14.1 in c:\\users\\dimzog\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from -r requirements.txt (line 7)) (0.14.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\dimzog\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pandas==1.0.1->-r requirements.txt (line 2)) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\dimzog\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pandas==1.0.1->-r requirements.txt (line 2)) (2.8.1)\n",
      "Requirement already satisfied: six in c:\\users\\dimzog\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from nltk==3.4.5->-r requirements.txt (line 4)) (1.14.0)\n",
      "Requirement already satisfied: scipy>=0.17.0 in c:\\users\\dimzog\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn==0.22.1->-r requirements.txt (line 5)) (1.4.1)\n",
      "Requirement already satisfied: matplotlib>=2.1.2 in c:\\users\\dimzog\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from seaborn==0.10.0->-r requirements.txt (line 6)) (3.1.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\dimzog\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib>=2.1.2->seaborn==0.10.0->-r requirements.txt (line 6)) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\dimzog\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib>=2.1.2->seaborn==0.10.0->-r requirements.txt (line 6)) (2.4.6)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\dimzog\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from matplotlib>=2.1.2->seaborn==0.10.0->-r requirements.txt (line 6)) (1.1.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\dimzog\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib>=2.1.2->seaborn==0.10.0->-r requirements.txt (line 6)) (41.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt\n",
    "\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Scikit Imports\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Save model checkpoints\n",
    "from joblib import dump\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load json data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39774, 3)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_json('data/train.json',  dtype={'id': 'int64', 'cuisine': 'str', 'ingredients': 'str'})\n",
    "train_df = train_df[train_df.ingredients.str.len() > 1]\n",
    "\n",
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to lowercase, remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39774, 4)\n"
     ]
    }
   ],
   "source": [
    "# Convert to lowercase\n",
    "train_df['seperated_ingredients'] = train_df.ingredients.str.lower()\n",
    "\n",
    "# Remove punctuation\n",
    "reg = re.compile('[^\\w\\s\\,]')\n",
    "train_df.seperated_ingredients.replace(reg, '', inplace=True)\n",
    "\n",
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cuisine</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>seperated_ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10259</td>\n",
       "      <td>greek</td>\n",
       "      <td>['romaine lettuce', 'black olives', 'grape tom...</td>\n",
       "      <td>romaine lettuce, black olives, grape tomatoes,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25693</td>\n",
       "      <td>southern_us</td>\n",
       "      <td>['plain flour', 'ground pepper', 'salt', 'toma...</td>\n",
       "      <td>plain flour, ground pepper, salt, tomatoes, gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20130</td>\n",
       "      <td>filipino</td>\n",
       "      <td>['eggs', 'pepper', 'salt', 'mayonaise', 'cooki...</td>\n",
       "      <td>eggs, pepper, salt, mayonaise, cooking oil, gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22213</td>\n",
       "      <td>indian</td>\n",
       "      <td>['water', 'vegetable oil', 'wheat', 'salt']</td>\n",
       "      <td>water, vegetable oil, wheat, salt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13162</td>\n",
       "      <td>indian</td>\n",
       "      <td>['black pepper', 'shallots', 'cornflour', 'cay...</td>\n",
       "      <td>black pepper, shallots, cornflour, cayenne pep...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id      cuisine                                        ingredients  \\\n",
       "0  10259        greek  ['romaine lettuce', 'black olives', 'grape tom...   \n",
       "1  25693  southern_us  ['plain flour', 'ground pepper', 'salt', 'toma...   \n",
       "2  20130     filipino  ['eggs', 'pepper', 'salt', 'mayonaise', 'cooki...   \n",
       "3  22213       indian        ['water', 'vegetable oil', 'wheat', 'salt']   \n",
       "4  13162       indian  ['black pepper', 'shallots', 'cornflour', 'cay...   \n",
       "\n",
       "                               seperated_ingredients  \n",
       "0  romaine lettuce, black olives, grape tomatoes,...  \n",
       "1  plain flour, ground pepper, salt, tomatoes, gr...  \n",
       "2  eggs, pepper, salt, mayonaise, cooking oil, gr...  \n",
       "3                  water, vegetable oil, wheat, salt  \n",
       "4  black pepper, shallots, cornflour, cayenne pep...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39774, 4)\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "train_df['seperated_ingredients'] = train_df.seperated_ingredients.apply(lambda x: ''.join([lemmatizer.lemmatize(w) for w in nltk.word_tokenize(x)]))\n",
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cuisine</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>seperated_ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10259</td>\n",
       "      <td>greek</td>\n",
       "      <td>['romaine lettuce', 'black olives', 'grape tom...</td>\n",
       "      <td>romainelettuce,blackolive,grapetomato,garlic,p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25693</td>\n",
       "      <td>southern_us</td>\n",
       "      <td>['plain flour', 'ground pepper', 'salt', 'toma...</td>\n",
       "      <td>plainflour,groundpepper,salt,tomato,groundblac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20130</td>\n",
       "      <td>filipino</td>\n",
       "      <td>['eggs', 'pepper', 'salt', 'mayonaise', 'cooki...</td>\n",
       "      <td>egg,pepper,salt,mayonaise,cookingoil,greenchil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22213</td>\n",
       "      <td>indian</td>\n",
       "      <td>['water', 'vegetable oil', 'wheat', 'salt']</td>\n",
       "      <td>water,vegetableoil,wheat,salt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13162</td>\n",
       "      <td>indian</td>\n",
       "      <td>['black pepper', 'shallots', 'cornflour', 'cay...</td>\n",
       "      <td>blackpepper,shallot,cornflour,cayennepepper,on...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id      cuisine                                        ingredients  \\\n",
       "0  10259        greek  ['romaine lettuce', 'black olives', 'grape tom...   \n",
       "1  25693  southern_us  ['plain flour', 'ground pepper', 'salt', 'toma...   \n",
       "2  20130     filipino  ['eggs', 'pepper', 'salt', 'mayonaise', 'cooki...   \n",
       "3  22213       indian        ['water', 'vegetable oil', 'wheat', 'salt']   \n",
       "4  13162       indian  ['black pepper', 'shallots', 'cornflour', 'cay...   \n",
       "\n",
       "                               seperated_ingredients  \n",
       "0  romainelettuce,blackolive,grapetomato,garlic,p...  \n",
       "1  plainflour,groundpepper,salt,tomato,groundblac...  \n",
       "2  egg,pepper,salt,mayonaise,cookingoil,greenchil...  \n",
       "3                      water,vegetableoil,wheat,salt  \n",
       "4  blackpepper,shallot,cornflour,cayennepepper,on...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 unique labels: ['greek' 'southern_us' 'filipino' 'indian' 'jamaican' 'spanish' 'italian'\n",
      " 'mexican' 'chinese' 'british' 'thai' 'vietnamese' 'cajun_creole'\n",
      " 'brazilian' 'french' 'japanese' 'irish' 'korean' 'moroccan' 'russian']\n"
     ]
    }
   ],
   "source": [
    "uniq = train_df.cuisine.unique()\n",
    "\n",
    "print(f'{len(uniq)} unique labels: {uniq}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gridsearch using Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ...\n",
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   19.3s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  7.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1080 out of 1080 | elapsed: 10.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "K-fold Score: 0.79.\n",
      "Best Parameters:\n",
      "\n",
      "clf__alpha: 1e-05\n",
      "clf__penalty: elasticnet\n",
      "tfidf__norm: l2\n",
      "vect__max_df: 1.0\n",
      "vect__min_df: 1\n",
      "vect__ngram_range: (1, 2)\n",
      "Accuracy: 78.57 %.\n"
     ]
    }
   ],
   "source": [
    "df = train_df.copy()\n",
    "\n",
    "# Split Dataset into test and train, using 80-20 ratio.\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.ingredients, df.cuisine, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "def tokenizer(text):\n",
    "    return nltk.tokenize.casual.TweetTokenizer().tokenize(text)\n",
    "\n",
    "\n",
    "# Construct a pipeline in order to use vectorizer => transformer => classifier easier.\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(tokenizer=tokenizer, max_features=None,\n",
    "                             encoding='utf-8', lowercase=False)),\n",
    "    ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "    ('clf', SGDClassifier(loss='hinge', random_state=42, penalty='elasticnet')),\n",
    "])\n",
    "\n",
    "# Tuning parameters. Change loss to use other classifiers.\n",
    "parameters = {\n",
    "    'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    'vect__min_df': (1, 5, 10),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),\n",
    "    'tfidf__norm': ('l1', 'l2'),\n",
    "    'clf__alpha': (0.0001, 0.00001),\n",
    "    'clf__penalty': ('l1', 'l2', 'elasticnet'),\n",
    "    # 'clf__loss': ('log', 'modified_huber', 'epsilon_insensitive', 'perceptron')\n",
    "}\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    grid_search = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "    print(f'Training ...')\n",
    "\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(f'\\nK-fold Score: {grid_search.best_score_:.2f}.')\n",
    "\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    print('Best Parameters:\\n')\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(f'{param_name}: {best_parameters[param_name]}')\n",
    "\n",
    "    # dump(grid_search.best_estimator_, '../trained_pipeline.pkl', compress=0)\n",
    "\n",
    "    acc = (grid_search.predict(X_test) == y_test).mean()\n",
    "    print(f'Accuracy: {acc*100:0.2f} %.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
